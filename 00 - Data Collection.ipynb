{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e935a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74de293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://this-person-does-not-exist.com'\n",
    "\n",
    "if os.path.isdir('./data/generated/High Res/') is False:\n",
    "    os.makedirs('./data/generated/High Res/')\n",
    "    \n",
    "path = './data/generated/High Res/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5708496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 20.0% Completion: Retrieved 10 of targeted 50 images.\n",
      "Current Execution Time: 40.0 seconds. \n",
      "\n",
      "At 40.0% Completion: Retrieved 20 of targeted 50 images.\n",
      "Current Execution Time: 74.0 seconds. \n",
      "\n",
      "At 60.0% Completion: Retrieved 30 of targeted 50 images.\n",
      "Current Execution Time: 105.0 seconds. \n",
      "\n",
      "At 80.0% Completion: Retrieved 40 of targeted 50 images.\n",
      "Current Execution Time: 144.0 seconds. \n",
      "\n",
      "At 100.0% Completion: Retrieved 50 of targeted 50 images.\n",
      "Current Execution Time: 180.0 seconds. \n",
      "\n",
      "Final Results: Retrieved 50 of targeted 50 images.\n",
      "Current Execution Time: 180.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate retrieval of full resolution images\n",
    "\n",
    "time_0 = time.time()\n",
    "\n",
    "retrieve_n = 50\n",
    "retrieved = 0\n",
    "\n",
    "for image in range(retrieve_n):\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    good_status = res.status_code == 200\n",
    "    wait_cycle = 0\n",
    "    failed_connection = False\n",
    "    \n",
    "    while not good_status:\n",
    "        wait_cycle += 1\n",
    "        print('Site did not respond. Retrying...')\n",
    "        if wait_cycle > 5:\n",
    "            print(f'Could not reach site. Terminating request. \\\n",
    "            Loop collected {retrieved} out of {retrieve_n} image(s) prior to lost connection.')\n",
    "            failed_connection = True\n",
    "            break\n",
    "        time.sleep(3)\n",
    "        res = requests.get(url)\n",
    "        good_status = res.status_code == 200\n",
    "\n",
    "    if failed_connection:\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    image_json = soup.find('img', {'id': 'avatar'})\n",
    "    image_link = url + image_json['src']\n",
    "    image_name = re.findall(\"avatar\\S+.jpg\", image_link)[0]\n",
    "    image_path = path + '/' + image_name\n",
    "    image_res = requests.get(image_link)\n",
    "\n",
    "    if image_res.status_code != 200:\n",
    "        continue\n",
    "\n",
    "    file = open(image_path, 'wb')\n",
    "    file.write(image_res.content)\n",
    "    file.close()\n",
    "    \n",
    "    retrieved += 1\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "    if (image + 1) % (retrieve_n//5) == 0:\n",
    "        print(f'At {round(((image + 1) / retrieve_n) * 100, 1)}% Completion: Retrieved {retrieved} of targeted {retrieve_n} images.')\n",
    "        print(f'Current Execution Time: {round((time.time() - time_0), 0)} seconds. \\n')\n",
    "\n",
    "print(f'Final Results: Retrieved {retrieved} of targeted {retrieve_n} images.')\n",
    "print(f'Current Execution Time: {round((time.time() - time_0), 0)} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bfb2672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site did not respond. Retrying...\n",
      "Site did not respond. Retrying...\n",
      "Site did not respond. Retrying...\n",
      "Site did not respond. Retrying...\n",
      "Site did not respond. Retrying...\n",
      "Site did not respond. Retrying...\n",
      "Could not reach site. Terminating request. Loop collected 0 image(s) prior to lost connection.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    wait_cycle = 0\n",
    "    failed_connection = False\n",
    "    \n",
    "    while 100 != 200:\n",
    "        wait_cycle += 1\n",
    "        print('Site did not respond. Retrying...')\n",
    "        if wait_cycle > 5:\n",
    "            print(f'Could not reach site. Terminating request. Loop collected {i} image(s) prior to lost connection.')\n",
    "            failed_connection = True\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    if failed_connection:\n",
    "        break\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30158d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image resizing from: https://www.tutorialkart.com/opencv/python/opencv-python-resize-image/\n",
    "\n",
    "img1 = cv2.imread('./data/generated/High Res/avatar-008390911eb28a25b6dcbbea9cb607ac.jpg', cv2.IMREAD_UNCHANGED)\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d670149",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 252\n",
    "height = 252\n",
    "dim = (width, height)\n",
    "resized = cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d74b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image 1', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8efcefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "image_json = soup.find('img', {'id': 'avatar'})\n",
    "image_link = url + image_json['src']\n",
    "image_name = re.findall(\"avatar\\S+.jpg\", image_link)[0]\n",
    "image_path = path + '/' + image_name\n",
    "image_res = requests.get(image_link, stream=True).raw\n",
    "\n",
    "# raw image handling from: https://stackoverflow.com/questions/57539233/how-to-open-an-image-from-an-url-with-opencv-using-requests-from-python\n",
    "image = np.asarray(bytearray(image_res.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "width = 256\n",
    "height = 256\n",
    "dim = (width, height)\n",
    "resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "cv2.imshow('Image 1', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb76590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!IMPORTANT!! Do not 'x' out of image popup; press any key to close. Will break jupyter!\n",
    "\n",
    "# See the difference in downscaling results based on interpolation type\n",
    "\n",
    "res = requests.get(url)\n",
    "good_status = res.status_code == 200\n",
    "wait_cycle = 0\n",
    "failed_connection = False\n",
    "\n",
    "while not good_status:\n",
    "    wait_cycle += 1\n",
    "    print('Site did not respond. Retrying...')\n",
    "    if wait_cycle > 5:\n",
    "        print(f'Could not reach site. Terminating request. \\\n",
    "        Loop collected {retrieved} out of {retrieve_n} image(s) prior to lost connection.')\n",
    "        failed_connection = True\n",
    "        break\n",
    "    time.sleep(3)\n",
    "    res = requests.get(url)\n",
    "    good_status = res.status_code == 200\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "image_json = soup.find('img', {'id': 'avatar'})\n",
    "image_link = url + image_json['src']\n",
    "image_name = re.findall(\"avatar\\S+.jpg\", image_link)[0]\n",
    "image_path = path + '/' + image_name\n",
    "image_res = requests.get(image_link, stream=True).raw\n",
    "\n",
    "#     if image_res.status_code != 200:\n",
    "#         continue\n",
    "\n",
    "image = np.asarray(bytearray(image_res.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "width = 128\n",
    "height = 128\n",
    "dim = (width, height)\n",
    "resized = cv2.resize(image, dim, interpolation = cv2.INTER_LANCZOS4)\n",
    "\n",
    "\n",
    "resized_nearest = cv2.resize(image, dim, interpolation = cv2.INTER_NEAREST) # Pretty bad\n",
    "resized_linear = cv2.resize(image, dim, interpolation = cv2.INTER_LINEAR) # Decent, but a little blurry\n",
    "resized_area = cv2.resize(image, dim, interpolation = cv2.INTER_AREA) # Decent, but pixelated\n",
    "resized_cubic = cv2.resize(image, dim, interpolation = cv2.INTER_CUBIC) # Impressive!\n",
    "resized_lanczos = cv2.resize(image, dim, interpolation = cv2.INTER_LANCZOS4) # Very impressive!\n",
    "\n",
    "# process for displaying side-by-side images from: https://www.geeksforgeeks.org/how-to-display-multiple-images-in-one-window-using-opencv-python/\n",
    "horizontal = np.concatenate((resized_nearest, resized_linear, resized_area, resized_cubic, resized_lanczos), axis=1)\n",
    "\n",
    "cv2.imshow('Image 1', horizontal)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # !!IMPORTANT!! Do not 'x' out of image popup; press any key to close. Will break jupyter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37753cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3145728"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f7e61e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 2.0 seconds\n"
     ]
    }
   ],
   "source": [
    "time_0 = time.time()\n",
    "time.sleep(2)\n",
    "print(f'Execution Time: {round((time.time() - time_0), 0)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d5486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_path(path_string):\n",
    "    \n",
    "    if os.path.isdir(path_string) is False:\n",
    "        os.makedirs(path_string)\n",
    "\n",
    "    return path_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c249c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = 'INTER_LANCZOS4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d1541d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(cv2, interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7828252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-res (128 x 128px) image collection\n",
    "\n",
    "def collect_low_res(path, retrieve_n=500, interp='INTER_AREA'):\n",
    "    \"\"\"Collect downconverted 128 x 128px resolution images from the website 'this-person-does-not-exist.com'.\n",
    "\n",
    "    Keyword arguments:\n",
    "    path -- location to place collected images\n",
    "    retrieve_n -- the number of images to be harvested per call of the function (default 500)\n",
    "    interp -- the openCV interpolation method to be used when resizing the image \\\n",
    "            Options are: 'INTER_NEAREST', 'INTER_LINEAR', 'INTER_AREA', 'INTER_CUBIC', and 'INTER_LANCZOS4'\n",
    "    \"\"\"\n",
    "    \n",
    "    time_0 = time.time()\n",
    "\n",
    "    path = path\n",
    "    retrieve_n = retrieve_n\n",
    "    retrieved = 0\n",
    "\n",
    "    for image in range(retrieve_n):\n",
    "\n",
    "        res = requests.get(url)\n",
    "        good_status = res.status_code == 200\n",
    "        wait_cycle = 0\n",
    "        failed_connection = False\n",
    "\n",
    "        while not good_status:\n",
    "            wait_cycle += 1\n",
    "            print('Site did not respond. Retrying...')\n",
    "            if wait_cycle > 5:\n",
    "                print(f'Could not reach site. Terminating request. \\\n",
    "                Loop collected {retrieved} out of {retrieve_n} image(s) prior to lost connection.')\n",
    "                failed_connection = True\n",
    "                break\n",
    "            time.sleep(3)\n",
    "            res = requests.get(url)\n",
    "            good_status = res.status_code == 200\n",
    "\n",
    "        if failed_connection:\n",
    "            break\n",
    "\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        image_json = soup.find('img', {'id': 'avatar'})\n",
    "        image_link = url + image_json['src']\n",
    "        image_name = re.findall(\"avatar\\S+.jpg\", image_link)[0]\n",
    "        image_path = path + '/' + image_name\n",
    "        image_res = requests.get(image_link, stream=True).raw\n",
    "\n",
    "    #     if image_res.status_code != 200:\n",
    "    #         continue\n",
    "\n",
    "        image = np.asarray(bytearray(image_res.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if image.size == 0 or None:\n",
    "            print('Failed to collect image')\n",
    "            continue\n",
    "\n",
    "        width = 128\n",
    "        height = 128\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(image, dim, interpolation = getattr(cv2, interp))\n",
    "\n",
    "        cv2.imwrite(image_path, resized)\n",
    "\n",
    "        time.sleep(3)\n",
    "        retrieved += 1\n",
    "\n",
    "    print(f'Retrieved {retrieved} of targeted {retrieve_n} images.')\n",
    "    print(f'Execution Time: {round((time.time() - time_0), 0)} seconds')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5830e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_low_res = generate_path('./data/generated/lanczos4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3d423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 650 of targeted 650 images.\n",
      "Execution Time: 3829.0 seconds\n"
     ]
    }
   ],
   "source": [
    "collect_low_res(path_low_res, retrieve_n=650, interp='INTER_LANCZOS4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e4a435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th># PubFig Dataset v1.2 - eval_urls.txt - http://www.cs.columbia.edu/CAVE/databases/pubfig/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th>person</th>\n",
       "      <th>imagenum</th>\n",
       "      <th>url</th>\n",
       "      <th>rect</th>\n",
       "      <td>md5sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Aaron Eckhart</th>\n",
       "      <th>1</th>\n",
       "      <th>http://farm1.static.flickr.com/119/288329997_19ebf1d7b3_o.jpg</th>\n",
       "      <th>248,92,338,182</th>\n",
       "      <th>a980a9e21c90ff62e57345fad53a56c8</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>http://farm1.static.flickr.com/35/99344798_f2ad604eda_o.jpg</th>\n",
       "      <th>267,138,419,290</th>\n",
       "      <th>8b2bc3a7a3b4a9d5826cd31ac9254924</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>http://2.bp.blogspot.com/_DxSfGxvclek/SH-K403dDuI/AAAAAAAAAC8/6TGJ67y8kZk/s320/Aaron%2BEckhart.jpg</th>\n",
       "      <th>32,39,94,101</th>\n",
       "      <th>994b9bfd1464936488458d2679e05520</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>http://2.bp.blogspot.com/_biK-MLwOHEc/RtXJ3nA4y5I/AAAAAAAAALM/fMGxP5sRK10/s320/aaroneckhart.jpg</th>\n",
       "      <th>75,66,183,174</th>\n",
       "      <th>d50214036344a000cdf1e68832acf33f</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">William Macy</th>\n",
       "      <th>96</th>\n",
       "      <th>http://farm1.static.flickr.com/62/207526936_d9d5d4a75e_o.jpg</th>\n",
       "      <th>504,174,694,364</th>\n",
       "      <th>2df2257b04cd4f3c23ce95d67e867e2c</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <th>http://farm1.static.flickr.com/98/243909925_1aeba9954c_o.jpg</th>\n",
       "      <th>275,182,429,336</th>\n",
       "      <th>af91f80483ef3aa34ca2f80ab91c09b3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <th>http://farm1.static.flickr.com/91/245712735_4d83608e75_o.jpg</th>\n",
       "      <th>908,564,1200,857</th>\n",
       "      <th>bd1e84385beed6c5dca4f90d044ddda3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <th>http://farm1.static.flickr.com/33/39937487_72abc68cc2_o.jpg</th>\n",
       "      <th>373,259,479,365</th>\n",
       "      <th>d724cfd1decebac4d6ee79e799807f88</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>http://farm1.static.flickr.com/31/39937508_3fec58c312_o.jpg</th>\n",
       "      <th>180,298,442,560</th>\n",
       "      <th>d1910cdf30aa90c3436d69c6e18e35f4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42462 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          # PubFig Dataset v1.2 - eval_urls.txt - http://www.cs.columbia.edu/CAVE/databases/pubfig/\n",
       "#             person imagenum                                           url              rect                                                                         md5sum                                       \n",
       "Aaron Eckhart 1      http://farm1.static.flickr.com/119/288329997_19... 248,92,338,182   a980a9e21c90ff62e57345fad53a56c8                                                NaN                                       \n",
       "              2      http://farm1.static.flickr.com/35/99344798_f2ad... 267,138,419,290  8b2bc3a7a3b4a9d5826cd31ac9254924                                                NaN                                       \n",
       "              4      http://2.bp.blogspot.com/_DxSfGxvclek/SH-K403dD... 32,39,94,101     994b9bfd1464936488458d2679e05520                                                NaN                                       \n",
       "              5      http://2.bp.blogspot.com/_biK-MLwOHEc/RtXJ3nA4y... 75,66,183,174    d50214036344a000cdf1e68832acf33f                                                NaN                                       \n",
       "...                                                                                                                                                                      ...                                       \n",
       "William Macy  96     http://farm1.static.flickr.com/62/207526936_d9d... 504,174,694,364  2df2257b04cd4f3c23ce95d67e867e2c                                                NaN                                       \n",
       "              97     http://farm1.static.flickr.com/98/243909925_1ae... 275,182,429,336  af91f80483ef3aa34ca2f80ab91c09b3                                                NaN                                       \n",
       "              98     http://farm1.static.flickr.com/91/245712735_4d8... 908,564,1200,857 bd1e84385beed6c5dca4f90d044ddda3                                                NaN                                       \n",
       "              99     http://farm1.static.flickr.com/33/39937487_72ab... 373,259,479,365  d724cfd1decebac4d6ee79e799807f88                                                NaN                                       \n",
       "              100    http://farm1.static.flickr.com/31/39937508_3fec... 180,298,442,560  d1910cdf30aa90c3436d69c6e18e35f4                                                NaN                                       \n",
       "\n",
       "[42462 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('https://www.cs.columbia.edu/CAVE/databases/pubfig/download/eval_urls.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5826aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_link = 'https://www.cs.columbia.edu/CAVE/databases/pubfig/download/eval_urls.txt'\n",
    "real_resp = requests.get(real_link)\n",
    "output = open('./data/real/real_images.txt', 'wb')\n",
    "output.write(real_resp.content)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e1eeb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach to delete lines found here: https://pynative.com/python-delete-lines-from-file/\n",
    "\n",
    "with open('./data/real/real_images.txt', 'r') as input_data:\n",
    "    lines = input_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf1d3b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# PubFig Dataset v1.2 - eval_urls.txt - http://www.cs.columbia.edu/CAVE/databases/pubfig/\\n',\n",
       " '#\\tperson\\timagenum\\turl\\trect\\tmd5sum\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999a51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/real/real_images.txt', 'w') as input_data:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number == 1:\n",
    "            input_data.write(line.strip('#\\t'))\n",
    "        else:\n",
    "            if number not in [0]:\n",
    "                input_data.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7f4b512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person\\timagenum\\turl\\trect\\tmd5sum\\n',\n",
       " 'Aaron Eckhart\\t1\\thttp://farm1.static.flickr.com/119/288329997_19ebf1d7b3_o.jpg\\t248,92,338,182\\ta980a9e21c90ff62e57345fad53a56c8\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/real/real_images.txt', 'r') as input_data:\n",
    "    lines = input_data.readlines()\n",
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c97cb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42461, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real = pd.read_csv('./data/real/real_images.txt', sep='\\t')\n",
    "df_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a570ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://fanphotosource.com/harrison-ford/photos/harrison-ford-and_elizabeth-taylor/harrison-ford-elizabeth-taylor-0000101.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_link = df_real['url'].sample(random_state=17).values[0]\n",
    "real_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da5a75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_link = 'http://www.firstshowing.net/img/harvey-dent-believe-350w.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "450a36e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'248,92,338,182'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real.loc[0, 'rect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d495146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[237, 102, 333, 198]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rect = '237,102,333,198'\n",
    "rect_vals = [int(x) for x in rect.split(',')]\n",
    "rect_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f2a21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[169, 265]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_center = [(rect_vals[0]-rect_vals[1])//2 + rect_vals[1],(rect_vals[2]-rect_vals[3])//2 + rect_vals[3]]\n",
    "face_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4e0d926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 135)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rect_height = rect_vals[0] - rect_vals[1]\n",
    "rect_width = rect_vals[2] - rect_vals[3]\n",
    "rect_height, rect_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443e469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_height = rect_height * 15//10\n",
    "padded_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02689542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_width = rect_width * 15//10\n",
    "padded_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03553e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_square = max(padded_height, padded_width)\n",
    "px_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33e3c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_link = real_link\n",
    "image_res = requests.get(image_link, stream=True).raw\n",
    "\n",
    "# raw image handling from: https://stackoverflow.com/questions/57539233/how-to-open-an-image-from-an-url-with-opencv-using-requests-from-python\n",
    "image = np.asarray(bytearray(image_res.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "# crop image\n",
    "rect = '237,102,333,198' # this will be brought in from the dataframe\n",
    "rect_vals = [int(x) for x in rect.split(',')]\n",
    "face_center = [(rect_vals[0]-rect_vals[1])//2 + rect_vals[1],(rect_vals[2]-rect_vals[3])//2 + rect_vals[3]]\n",
    "rect_height = rect_vals[0] - rect_vals[1]\n",
    "rect_width = rect_vals[2] - rect_vals[3]\n",
    "padded_height = rect_height * 15//10\n",
    "padded_width = rect_width * 15//10\n",
    "px_square = max(padded_height, padded_width) # produce a square that is sure to capture target face\n",
    "offset = px_square//2\n",
    "\n",
    "image = image[face_center[0]-offset:face_center[0]+offset, face_center[1]-offset:rect_vals[2]+offset]\n",
    "\n",
    "# cv2.imshow('Image 1', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "width = 256\n",
    "height = 256\n",
    "dim = (width, height)\n",
    "resized_nearest = cv2.resize(image, dim, interpolation = cv2.INTER_NEAREST) # Pretty bad\n",
    "resized_linear = cv2.resize(image, dim, interpolation = cv2.INTER_LINEAR) # Decent, but a little blurry\n",
    "resized_area = cv2.resize(image, dim, interpolation = cv2.INTER_AREA) # Decent, but pixelated\n",
    "resized_cubic = cv2.resize(image, dim, interpolation = cv2.INTER_CUBIC) # Impressive!\n",
    "resized_lanczos = cv2.resize(image, dim, interpolation = cv2.INTER_LANCZOS4) # Very impressive!\n",
    "\n",
    "# process for displaying side-by-side images from: https://www.geeksforgeeks.org/how-to-display-multiple-images-in-one-window-using-opencv-python/\n",
    "horizontal = np.concatenate((resized_nearest, resized_linear, resized_area, resized_cubic, resized_lanczos), axis=1)\n",
    "\n",
    "# cv2.imshow('Image 1', horizontal)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('Window 1', resized_lanczos)\n",
    "cv2.imshow('Window 2', resized_nearest)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a36187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['http://farm1.static.flickr.com/119/288329997_19ebf1d7b3_o.jpg',\n",
       "       'http://farm1.static.flickr.com/35/99344798_f2ad604eda_o.jpg',\n",
       "       'http://2.bp.blogspot.com/_DxSfGxvclek/SH-K403dDuI/AAAAAAAAAC8/6TGJ67y8kZk/s320/Aaron%2BEckhart.jpg',\n",
       "       'http://2.bp.blogspot.com/_biK-MLwOHEc/RtXJ3nA4y5I/AAAAAAAAALM/fMGxP5sRK10/s320/aaroneckhart.jpg',\n",
       "       'http://3.bp.blogspot.com/_bto58WjLomw/Rk1yrB-rEXI/AAAAAAAABGo/dy33tJJsjSE/s400/aaron_eckhart3.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real['url'].values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e78bd9",
   "metadata": {},
   "source": [
    "## Experiment: Test whether preprocessing/interpolation of the synthetic images is 'giving away' the synthetics in the model\n",
    "\n",
    "The 128 x 128px data set from Kaggle, while being very convenient and having my deep appreciation, does not specify how the full resolution images from the FFHQ database were downconverted. This poses a problem due to the fact that I apply a downconversion on the raw 1024 x 1024px synthetic images upon retrieval, and in turn must select an interpolation method to execute the downconversion. There is a potentiality that the methods used for downconversion between real and synthetic images differ, and that there may be artifacts to either process that are present in the images purely due to preprocessing, and could be a factor in the neural net's ability to distinguish one from the other. Here, I bring in a small set of full resolution real images and apply identical interpolation methods for the downconversion that I have applied to the raw synthetic images, so that a comparison model can be built and relative performance can be evaluated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd25c62",
   "metadata": {},
   "source": [
    "#### Downconvert full resolution real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb68901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_imgs(full_res_dir, destination_dir, interp, width=128, height=128):\n",
    "    \n",
    "    destination_dir = destination_dir + interp + '/'\n",
    "    \n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.mkdir(destination_dir)\n",
    "\n",
    "    for image_name in os.listdir(full_res_dir):\n",
    "\n",
    "            image_path = full_res_dir + image_name\n",
    "            image = cv2.imread(image_path)\n",
    "                        \n",
    "            dim = (width, height)\n",
    "            resized = cv2.resize(image, dim, interpolation = getattr(cv2, interp))\n",
    "#             print((destination_dir + interp + '_' + image_name))\n",
    "            cv2.imwrite((destination_dir + interp + '_' + image_name), resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "214d5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_res_dir = './data/real/FFHQ-high-res/69000/'\n",
    "destination_dir = './data/real/FFHQ-high-res/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4961e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_imgs(full_res_dir, destination_dir, 'INTER_AREA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "163d1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale_imgs(full_res_dir, destination_dir, 'INTER_LANCZOS4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75b96a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
